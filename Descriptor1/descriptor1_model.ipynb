{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93df33c-2cb5-4637-820d-2f05d759eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import  GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, balanced_accuracy_score\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb360b-db21-4dca-ac2c-dd05d28b1c08",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20ff8f99-3887-42ef-b5bc-5801d37f0f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1452, 147)\n"
     ]
    }
   ],
   "source": [
    "# X = np.load(\"balanced_features.npy\")\n",
    "# y = np.load(\"balanced_targets.npy\")\n",
    "\n",
    "X = np.load(\"Descriptor1_complete_features.npy\")  \n",
    "y = np.load(\"Descriptor1_complete_targets.npy\")   \n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3cefbc-f57c-42b8-bf85-2408c39c225d",
   "metadata": {},
   "source": [
    "# class imbalance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a032df-b851-4393-9af2-18d17a9872b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 969 samples (66.74%)\n",
      "Class 1: 483 samples (33.26%)\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Class {label}: {count} samples ({count/len(y):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e49a6-a0f9-4dc6-8297-dbe40dea68d3",
   "metadata": {},
   "source": [
    "# identifying columns with >= 99 % zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69938479-89bf-4043-bbef-ae3a4c928710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eig_col  zero_rate  nonzero_count\n",
      "     143   0.999311              1\n",
      "     128   0.999311              1\n",
      "     129   0.999311              1\n",
      "     130   0.999311              1\n",
      "     131   0.999311              1\n",
      "     132   0.999311              1\n",
      "     133   0.999311              1\n",
      "     134   0.999311              1\n",
      "     142   0.999311              1\n",
      "     136   0.999311              1\n",
      "     137   0.999311              1\n",
      "     138   0.999311              1\n",
      "     139   0.999311              1\n",
      "     140   0.999311              1\n",
      "     141   0.999311              1\n",
      "     135   0.999311              1\n",
      "     112   0.998623              2\n",
      "     113   0.998623              2\n",
      "     114   0.998623              2\n",
      "     115   0.998623              2\n",
      "     116   0.998623              2\n",
      "     117   0.998623              2\n",
      "     118   0.998623              2\n",
      "     121   0.998623              2\n",
      "     120   0.998623              2\n",
      "     122   0.998623              2\n",
      "     123   0.998623              2\n",
      "     124   0.998623              2\n",
      "     125   0.998623              2\n",
      "     126   0.998623              2\n",
      "     127   0.998623              2\n",
      "     119   0.998623              2\n",
      "     105   0.997245              4\n",
      "     104   0.997245              4\n",
      "     106   0.997245              4\n",
      "     107   0.997245              4\n",
      "     108   0.997245              4\n",
      "     109   0.997245              4\n",
      "     110   0.997245              4\n",
      "     111   0.997245              4\n",
      "      96   0.996556              5\n",
      "      97   0.996556              5\n",
      "      98   0.996556              5\n",
      "     102   0.996556              5\n",
      "     100   0.996556              5\n",
      "     101   0.996556              5\n",
      "     103   0.996556              5\n",
      "      99   0.996556              5\n",
      "      88   0.995179              7\n",
      "      90   0.995179              7\n",
      "      91   0.995179              7\n",
      "      89   0.995179              7\n",
      "      93   0.995179              7\n",
      "      92   0.995179              7\n",
      "      94   0.995179              7\n",
      "      95   0.995179              7\n",
      "      84   0.991736             12\n",
      "      85   0.991736             12\n",
      "      87   0.991736             12\n",
      "      86   0.991736             12\n",
      "      83   0.991047             13\n",
      "      82   0.991047             13\n",
      "      81   0.991047             13\n",
      "      72   0.990358             14\n",
      "      80   0.990358             14\n",
      "      79   0.990358             14\n",
      "      78   0.990358             14\n",
      "      77   0.990358             14\n",
      "      76   0.990358             14\n",
      "      75   0.990358             14\n",
      "      74   0.990358             14\n",
      "      73   0.990358             14\n",
      "      71   0.988292             17\n",
      "      70   0.988292             17\n",
      "      69   0.986915             19\n",
      "      68   0.986915             19\n",
      "      67   0.986226             20\n",
      "      66   0.986226             20\n",
      "      65   0.984848             22\n",
      "      64   0.984848             22\n",
      "      63   0.984160             23\n",
      "      62   0.984160             23\n",
      "      61   0.983471             24\n",
      "      60   0.983471             24\n",
      "      59   0.976584             34\n",
      "      58   0.960744             57\n",
      "      57   0.960055             58\n",
      "      56   0.960055             58\n",
      "      55   0.952479             69\n",
      "      54   0.952479             69\n",
      "      52   0.949725             73\n",
      "      53   0.949725             73\n",
      "      51   0.947658             76\n",
      "      50   0.946281             78\n",
      "      49   0.944215             81\n",
      "      48   0.944215             81\n",
      "      47   0.933196             97\n",
      "      46   0.933196             97\n",
      "      45   0.929752            102\n",
      "      44   0.929752            102\n",
      "\n",
      "Cols ≥99% zero (0-based): [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]\n"
     ]
    }
   ],
   "source": [
    "# first 144 \n",
    "X_eig = X[:, :144]\n",
    "\n",
    "# how often each column is zero \n",
    "zero_rate = (X_eig == 0).mean(axis=0)\n",
    "nonzero_count = (X_eig != 0).sum(axis=0)\n",
    "\n",
    "# sorted summary (most-zero first)\n",
    "order = np.argsort(-zero_rate)\n",
    "summary = pd.DataFrame({\n",
    "    \"eig_col\": order,                 # 0-based index within the 144 eig cols\n",
    "    \"zero_rate\": zero_rate[order],\n",
    "    \"nonzero_count\": nonzero_count[order]\n",
    "})\n",
    "print(summary.head(100).to_string(index=False))\n",
    "\n",
    "# columns that are ≥99% zero\n",
    "cols_99 = np.where(zero_rate >= 0.99)[0]\n",
    "print(\"\\nCols ≥99% zero (0-based):\", cols_99.tolist())        #index start from 0 \n",
    "#print(\"Cols ≥99% zero (1-based):\", (cols_99 + 1).tolist())   #index start from 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a379df7-1f8c-4661-8f48-ed1c2699a0fc",
   "metadata": {},
   "source": [
    "# keeping top 72 + meta data (charge/spin/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbb0a7a4-dff9-40c0-9d96-4ac5543c66e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed shape: (1452, 75)\n"
     ]
    }
   ],
   "source": [
    "# Eigenvalues + meta data \n",
    "K = 72 \n",
    "X = np.hstack([X[:, :K], X[:, -3:]])\n",
    "\n",
    "print( \"Trimmed shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3cc6f-6525-49e4-b3d7-f5fc7388e2a1",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88cc246-5a67-4873-9184-899553fa2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val size: 1161\n",
      "Test size: 291\n"
     ]
    }
   ],
   "source": [
    "# 20/80 split. \n",
    "# 20 % for our hold out test set \n",
    "# 80 % for hyperparam tuning, ...\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,        # preserve 66/34 balance\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train/Val size:\", X_trainval.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef87ec-63c4-4aef-a9df-a405143896c2",
   "metadata": {},
   "source": [
    "# XGB selecting k & params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5f2af0a-bace-414c-b394-19aa3f3a3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "22\n",
      "24\n",
      "25\n",
      "30\n",
      "32\n",
      "40\n",
      "48\n",
      "50\n",
      "60\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# neg = (y_trainval == 0).sum()\n",
    "# pos = (y_trainval == 1).sum()\n",
    "# spw = neg / max(pos, 1)\n",
    "\n",
    "K_list = [5,6,7,8,9,10,11,12,13,14,15,16, 17, 18,19,20,22, 24,25, 30, 32,40,48,50,60,72]\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# search space \n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8, 10],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\": [0, 1, 5],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "}\n",
    "\n",
    "# scoring metrics\n",
    "scoring = {\"bal_acc\": \"balanced_accuracy\", \"acc\": \"accuracy\"}\n",
    "\n",
    "results = []          # list of dicts per K\n",
    "search_by_K = {}      # keep the fitted search object to reuse the winner's best_estimator_\n",
    "\n",
    "for K in K_list:\n",
    "    print(K)\n",
    "    Xi = np.hstack([X_trainval[:, :K], X_trainval[:, -3:]]) #top k eigneval + 3 metadata\n",
    "    xgb = XGBClassifier(random_state=RANDOM_STATE, \n",
    "                        eval_metric=\"logloss\", \n",
    "                       # scale_pos_weight=spw\n",
    "                       )\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=xgb,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,\n",
    "        scoring=scoring,\n",
    "        refit=\"bal_acc\",\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0, \n",
    "    )\n",
    "    search.fit(Xi, y_trainval)\n",
    "\n",
    "    best_idx = search.best_index_\n",
    "    splits = inner_cv.get_n_splits()\n",
    "\n",
    "    # per-fold scores for std (balanced acc and accuracy)\n",
    "    bal_folds = [search.cv_results_[f\"split{i}_test_bal_acc\"][best_idx] for i in range(splits)]\n",
    "    acc_folds = [search.cv_results_[f\"split{i}_test_acc\"][best_idx]     for i in range(splits)]\n",
    "\n",
    "    rec = {\"K\": K,\n",
    "            \"bal_mean\": float(search.cv_results_[\"mean_test_bal_acc\"][best_idx]),\n",
    "            \"bal_std\":  float(np.std(bal_folds)),\n",
    "            \"acc_mean\": float(search.cv_results_[\"mean_test_acc\"][best_idx]),\n",
    "            \"acc_std\":  float(np.std(acc_folds)),\n",
    "            \"best_params\": search.best_params_,\n",
    "    }\n",
    "    results.append(rec)\n",
    "    search_by_K[K] = search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb52ae38-ed64-45e8-975e-ab6035c574bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGB RandomizedSearch (5-fold), per-K summary — sorted by balanced accuracy ===\n",
      " K   bal_mean  bal_sd   acc_mean  acc_sd \n",
      "10   0.801    0.024    0.838    0.015\n",
      " 8   0.800    0.026    0.830    0.020\n",
      "17   0.798    0.031    0.829    0.025\n",
      " 6   0.798    0.027    0.832    0.019\n",
      "25   0.798    0.024    0.832    0.015\n",
      "11   0.797    0.025    0.831    0.013\n",
      " 9   0.797    0.022    0.832    0.019\n",
      " 5   0.796    0.023    0.831    0.016\n",
      " 7   0.795    0.027    0.828    0.019\n",
      "14   0.795    0.024    0.832    0.015\n",
      "18   0.794    0.026    0.828    0.019\n",
      "24   0.794    0.026    0.832    0.016\n",
      "16   0.794    0.017    0.826    0.015\n",
      "20   0.794    0.025    0.829    0.017\n",
      "48   0.794    0.024    0.833    0.016\n",
      "30   0.793    0.021    0.828    0.014\n",
      "22   0.793    0.023    0.830    0.015\n",
      "19   0.793    0.025    0.832    0.016\n",
      "12   0.792    0.028    0.826    0.020\n",
      "40   0.792    0.027    0.826    0.022\n",
      "13   0.791    0.027    0.825    0.021\n",
      "32   0.790    0.027    0.823    0.017\n",
      "15   0.790    0.032    0.829    0.020\n",
      "60   0.789    0.030    0.828    0.020\n",
      "72   0.789    0.027    0.829    0.017\n",
      "50   0.787    0.026    0.823    0.022\n",
      "\n",
      ">>> Selected K* = 10 by BEST bal_acc (best bal_acc=0.801±0.024; acc_mean=0.838±0.015)\n",
      "Winner params: {'subsample': 0.8, 'n_estimators': 800, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 0, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "#  summary sorted by balanced accuracy\n",
    "results.sort(key=lambda d: d[\"bal_mean\"], reverse=True)\n",
    "\n",
    "print(\"\\n=== XGB RandomizedSearch (5-fold), per-K summary — sorted by balanced accuracy ===\")\n",
    "print(\" K   bal_mean  bal_sd   acc_mean  acc_sd \")\n",
    "for r in results:\n",
    "    print(f\"{r['K']:2d}   {r['bal_mean']:.3f}    {r['bal_std']:.3f}    \"\n",
    "          f\"{r['acc_mean']:.3f}    {r['acc_std']:.3f}\")\n",
    "\n",
    "# best k \n",
    "best = max(results, key=lambda d: (d[\"bal_mean\"], d[\"acc_mean\"], -d[\"K\"]))\n",
    "K_star = best[\"K\"]\n",
    "winner = best\n",
    "\n",
    "print(f\"\\n>>> Selected K* = {K_star} by BEST bal_acc \"\n",
    "      f\"(best bal_acc={best['bal_mean']:.3f}±{best['bal_std']:.3f}; \"\n",
    "      f\"acc_mean={best['acc_mean']:.3f}±{best['acc_std']:.3f})\")\n",
    "print(\"Winner params:\", winner.get(\"best_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74565f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoostTrain Set Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.965     0.985     0.974       775\n",
      "           1      0.968     0.927     0.947       386\n",
      "\n",
      "    accuracy                          0.966      1161\n",
      "   macro avg      0.966     0.956     0.961      1161\n",
      "weighted avg      0.966     0.966     0.965      1161\n",
      "\n",
      "Train Accuracy: 0.9655469422911284\n",
      "Train Balanced Acc: 0.9559886344643156\n",
      "Train ROC-AUC: 0.9947818819989972\n",
      "Train PR-AUC: 0.9884579780160743\n",
      "\n",
      "=== XGBoost Test Set Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.902     0.879       194\n",
      "           1      0.782     0.701     0.739        97\n",
      "\n",
      "    accuracy                          0.835       291\n",
      "   macro avg      0.820     0.802     0.809       291\n",
      "weighted avg      0.832     0.835     0.833       291\n",
      "\n",
      "Test Accuracy: 0.8350515463917526\n",
      "Test Balanced Acc: 0.8015463917525774\n",
      "Test ROC-AUC: 0.8816292911042618\n",
      "Test PR-AUC: 0.8134891671990787\n"
     ]
    }
   ],
   "source": [
    "# Refit on all train/val with K* and evaluate on test \n",
    "X_trainval_k = np.hstack([X_trainval[:, :K_star], X_trainval[:, -3:]])\n",
    "X_test_k     = np.hstack([X_test[:, :K_star],     X_test[:, -3:]])\n",
    "\n",
    "best_xgb = search_by_K[K_star].best_estimator_   # already refit on all train/val by RandomizedSearchCV\n",
    "best_xgb.fit(X_trainval_k, y_trainval)           #  re-fit \n",
    "\n",
    "# Train eval\n",
    "y_pred_tr = best_xgb.predict(X_trainval_k)\n",
    "y_prob_tr = best_xgb.predict_proba(X_trainval_k)[:, 1]\n",
    "print(\"\\n=== XGBoostTrain Set Performance ===\")\n",
    "print(classification_report(y_trainval, y_pred_tr, digits=3))\n",
    "print(\"Train Accuracy:\", accuracy_score(y_trainval, y_pred_tr))\n",
    "print(\"Train Balanced Acc:\", balanced_accuracy_score(y_trainval, y_pred_tr))\n",
    "print(\"Train ROC-AUC:\", roc_auc_score(y_trainval, y_prob_tr))\n",
    "print(\"Train PR-AUC:\", average_precision_score(y_trainval, y_prob_tr))\n",
    "\n",
    "y_pred_te = best_xgb.predict(X_test_k)\n",
    "y_prob_te = best_xgb.predict_proba(X_test_k)[:, 1]\n",
    "print(\"\\n=== XGBoost Test Set Performance ===\")\n",
    "print(classification_report(y_test, y_pred_te, digits=3))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_te))\n",
    "print(\"Test Balanced Acc:\", balanced_accuracy_score(y_test, y_pred_te))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_prob_te))\n",
    "print(\"Test PR-AUC:\", average_precision_score(y_test, y_prob_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487faa7-973d-422e-a830-716a26acbe80",
   "metadata": {},
   "source": [
    "# RF selecting K & params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c49e08ff-79d0-427e-a477-8e9d41e59a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "K_list = [9,10,11]\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "param_dist = {                                  #add lr later\n",
    "    \"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "    \"max_depth\": [None, 6, 10, 14],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.3, 0.5, 0.7],\n",
    "    \"bootstrap\": [True],\n",
    "    \"class_weight\": [\"balanced\", \"balanced_subsample\"],\n",
    "}\n",
    "\n",
    "# scoring \n",
    "scoring = {\"bal_acc\": \"balanced_accuracy\", \"acc\": \"accuracy\"}\n",
    "\n",
    "results = []          # list of dicts per K\n",
    "search_by_K = {}      # keep the fitted search object to reuse the winner's best_estimator_\n",
    "\n",
    "for K in K_list:\n",
    "    print(K)\n",
    "    Xi = np.hstack([X_trainval[:, :K], X_trainval[:, -3:]])  # top-K eig + 3 metadata\n",
    "    rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,\n",
    "        scoring=scoring,\n",
    "        refit=\"bal_acc\",\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0,\n",
    "    )\n",
    "    search.fit(Xi, y_trainval)\n",
    "\n",
    "    best_idx = search.best_index_\n",
    "    splits = inner_cv.get_n_splits()\n",
    "\n",
    "    # per-fold scores for std (balanced acc and accuracy)\n",
    "    bal_folds = [search.cv_results_[f\"split{i}_test_bal_acc\"][best_idx] for i in range(splits)]\n",
    "    acc_folds = [search.cv_results_[f\"split{i}_test_acc\"][best_idx]     for i in range(splits)]\n",
    "\n",
    "    rec = {\"K\": K,\n",
    "            \"bal_mean\": float(search.cv_results_[\"mean_test_bal_acc\"][best_idx]),\n",
    "            \"bal_std\":  float(np.std(bal_folds)),\n",
    "            \"acc_mean\": float(search.cv_results_[\"mean_test_acc\"][best_idx]),\n",
    "            \"acc_std\":  float(np.std(acc_folds)),\n",
    "            \"best_params\": search.best_params_,}\n",
    "            \n",
    "    results.append(rec)\n",
    "    search_by_K[K] = search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9417aec-7f7d-4e4d-bdb4-419e813ac001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  rf RandomizedSearch (5-fold), per-K summary — sorted by balanced accuracy ===\n",
      " K   bal_mean  bal_sd   acc_mean  acc_sd   \n",
      "11   0.796    0.018    0.823    0.014\n",
      "10   0.793    0.010    0.817    0.011\n",
      " 9   0.792    0.015    0.819    0.012\n",
      "\n",
      ">>> Selected K* = 11 by BEST bal_acc (bal_acc=0.796±0.018; acc_mean=0.823±0.014)\n",
      "Winner params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.7, 'max_depth': 10, 'class_weight': 'balanced', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Print summary sorted by balanced accuracy \n",
    "results.sort(key=lambda d: d[\"bal_mean\"], reverse=True)\n",
    "\n",
    "print(\"\\n===  rf RandomizedSearch (5-fold), per-K summary — sorted by balanced accuracy ===\")\n",
    "print(\" K   bal_mean  bal_sd   acc_mean  acc_sd   \")\n",
    "for r in results:\n",
    "    print(f\"{r['K']:2d}   {r['bal_mean']:.3f}    {r['bal_std']:.3f}    \"\n",
    "          f\"{r['acc_mean']:.3f}    {r['acc_std']:.3f}\")\n",
    "\n",
    "#  best k \n",
    "best = max(\n",
    "    results,\n",
    "    key=lambda d: (d[\"bal_mean\"], d[\"acc_mean\"], -d[\"K\"])\n",
    ")\n",
    "K_star = best[\"K\"]\n",
    "winner = best\n",
    "\n",
    "print(f\"\\n>>> Selected K* = {K_star} by BEST bal_acc \"\n",
    "      f\"(bal_acc={best['bal_mean']:.3f}±{best['bal_std']:.3f}; \"\n",
    "      f\"acc_mean={best['acc_mean']:.3f}±{best['acc_std']:.3f})\")\n",
    "print(\"Winner params:\", winner.get(\"best_params\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "677700bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train Set Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.966     0.975       775\n",
      "           1      0.935     0.966     0.950       386\n",
      "\n",
      "    accuracy                          0.966      1161\n",
      "   macro avg      0.959     0.966     0.962      1161\n",
      "weighted avg      0.967     0.966     0.967      1161\n",
      "\n",
      "Train Accuracy: 0.9664082687338501\n",
      "Train Balanced Acc: 0.9663864282132709\n",
      "Train ROC-AUC: 0.995059334781882\n",
      "Train PR-AUC: 0.9895330355028866\n",
      "\n",
      "=== Test Set Performance ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.878     0.856     0.867       194\n",
      "           1      0.725     0.763     0.744        97\n",
      "\n",
      "    accuracy                          0.825       291\n",
      "   macro avg      0.802     0.809     0.805       291\n",
      "weighted avg      0.827     0.825     0.826       291\n",
      "\n",
      "Test Accuracy: 0.8247422680412371\n",
      "Test Balanced Acc: 0.8092783505154639\n",
      "Test ROC-AUC: 0.8646242958869168\n",
      "Test PR-AUC: 0.7947454896110828\n"
     ]
    }
   ],
   "source": [
    "# Refit on all train/val with K* and evaluate on test.\n",
    "X_trainval_k = np.hstack([X_trainval[:, :K_star], X_trainval[:, -3:]])\n",
    "X_test_k     = np.hstack([X_test[:, :K_star],     X_test[:, -3:]])\n",
    "\n",
    "best_rf = search_by_K[K_star].best_estimator_   # already refit on all train/val by RandomizedSearchCV\n",
    "best_rf.fit(X_trainval_k, y_trainval)           # (harmless re-fit to be explicit)\n",
    "\n",
    "# Train eval\n",
    "y_pred_tr = best_rf.predict(X_trainval_k)\n",
    "y_prob_tr =best_rf.predict_proba(X_trainval_k)[:, 1]\n",
    "print(\"\\n=== Train Set Performance ===\")\n",
    "print(classification_report(y_trainval, y_pred_tr, digits=3))\n",
    "print(\"Train Accuracy:\", accuracy_score(y_trainval, y_pred_tr))\n",
    "print(\"Train Balanced Acc:\", balanced_accuracy_score(y_trainval, y_pred_tr))\n",
    "print(\"Train ROC-AUC:\", roc_auc_score(y_trainval, y_prob_tr))\n",
    "print(\"Train PR-AUC:\", average_precision_score(y_trainval, y_prob_tr))\n",
    "\n",
    "# Test eval \n",
    "y_pred_te = best_rf.predict(X_test_k)\n",
    "y_prob_te = best_rf.predict_proba(X_test_k)[:, 1]\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "print(classification_report(y_test, y_pred_te, digits=3))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_te))\n",
    "print(\"Test Balanced Acc:\", balanced_accuracy_score(y_test, y_pred_te))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_prob_te))\n",
    "print(\"Test PR-AUC:\", average_precision_score(y_test, y_prob_te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
